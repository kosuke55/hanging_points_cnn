# evaluation
## an example for pouring

1. Annotate objects using [pose_annotation_tool](https://github.com/kosuke55/pose_annotation_tool) after making an annotation directory with [make_annotation_dir.py](https://github.com/kosuke55/pose_annotation_tool/blob/master/utils/make_annotation_dir.py)

```
python make_coords_json.py -i '/media/kosuke55/SANDISK/meshdata/ycb_pouring_object_16/textured_urdf'
rosrun annotation_tool annotation_tool
```
2. Convert manual annotation format to coords json using [make_coords_json.py](https://github.com/kosuke55/pose_annotation_tool/blob/master/utils/make_coords_json.py).
```
python make_coords_json.py -i '/media/kosuke55/SANDISK/meshdata/ycb_pouring_object_16/textured_urdf/annotation_obj'
```

3. Create evaluation data with [renderer_create_eval.py](hanging_points_cnn/create_datase/renderer_create_eval.py) (only for sim data)
```
python renderer_create_eval.py -i /media/kosuke55/SANDISK/meshdata/ycb_pouring_object_16/textured_urdf -a /media/kosuke55/SANDISK/meshdata/ycb_pouring_object_16/textured_urdf/annotation_obj --task pouring
```

4. Calculate error with manual annotation.
```
python eval_ycb.py -i /media/kosuke55/SANDISK-2/meshdata/ycb_sim_eval_pouring -p <pretrained model> -t p -s <save direcgtor name. ex)eval_gan, eval_shapenet>
```

options
```
usage: eval_ycb.py [-h] [--input-dir INPUT_DIR]
                   [--annotation-dir ANNOTATION_DIR]
                   [--pretrained_model PRETRAINED_MODEL]
                   [--predict-depth PREDICT_DEPTH] [--task TASK] [--gui]
                   [--save-dir SAVE_DIR] [--save-3d-image] [--sim-data]
                   [--visualize-gt]

optional arguments:
  -h, --help            show this help message and exit
  --input-dir INPUT_DIR, -i INPUT_DIR
                        input directoryFor real data, the input directory has
                        the json files generated by make_coords_json.py. For
                        sim data, the input directory is created by
                        renderer_create_eval.py (default: /home/kosuke55/catki
                        n_ws/src/hanging_points_cnn/data/ycb_real_eval_pouring
                        )
  --annotation-dir ANNOTATION_DIR, -a ANNOTATION_DIR
                        annotation directory. required only for real data.
                        (default: /media/kosuke55/SANDISK/meshdata/ycb_pouring
                        _object_16/real_ycb_annotation_pouring)
  --pretrained_model PRETRAINED_MODEL, -p PRETRAINED_MODEL
                        Pretrained models (default: /media/kosuke55/SANDISK-2/
                        meshdata/shapenet_pouring_render/1222/pouring_shapenet
                        _20201229_2111_5epoch.pt)
  --predict-depth PREDICT_DEPTH, -pd PREDICT_DEPTH
                        predict-depth (default: 0)
  --task TASK, -t TASK  h(hanging) or p(pouring) (default: h)
  --gui, -g             visualzie (default: False)
  --save-dir SAVE_DIR, -s SAVE_DIR
                        directory to save evaluation result (default:
                        eval_gan)
  --save-3d-image, -s3i
                        Save 3D inference image (default: False)
  --sim-data, -sim      Use sim data (default: False)
  --visualize-gt, -vg   visualize groud truth data (default: False)
```

5. Read the evaluation result and print it for tex.
```
python read_hpnet_eval.py -g <gan diff directory> -s <shapenet diff directory>
```
